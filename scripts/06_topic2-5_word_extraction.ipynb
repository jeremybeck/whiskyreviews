{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the last notebook we identified that most of the review structure we are interested in for clustering based on nose, palate, and finish are concentrated in topics 2 and 5.  There are two separate ways we can get at that information in reviews:\n",
    "\n",
    " 1. Create a list of terms for topic 2 and 5 from the word topic probabilities\n",
    " 2. Run inference with LDA on each topic and use the per-token probabilities to extract terms\n",
    " \n",
    "In this notebook we will run both cases and compare outputs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from lda_funcs import *\n",
    "from gensim.corpora import Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restricted Dictionaries from LDA Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will go through the simple method of generating custom dictionaries for gensim based on the LDA output. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_topic_matrix = pd.read_pickle(os.getenv('DOMINO_WORKING_DIR') + '/data/processed/k7lemmas_pertopicprobs.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>sum</th>\n",
       "      <th>highest_prob_topic</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>token</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>$</th>\n",
       "      <td>4.554040e-03</td>\n",
       "      <td>1.322508e-06</td>\n",
       "      <td>5.524675e-03</td>\n",
       "      <td>3.675863e-03</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>6.960281e-05</td>\n",
       "      <td>7.256850e-03</td>\n",
       "      <td>0.021100</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.059977e-02</td>\n",
       "      <td>1.049358e-02</td>\n",
       "      <td>5.802063e-03</td>\n",
       "      <td>1.320193e-03</td>\n",
       "      <td>0.006939</td>\n",
       "      <td>2.476366e-03</td>\n",
       "      <td>1.348264e-02</td>\n",
       "      <td>0.051114</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>7.131748e-03</td>\n",
       "      <td>2.287706e-03</td>\n",
       "      <td>1.863797e-03</td>\n",
       "      <td>2.552788e-03</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>1.064249e-03</td>\n",
       "      <td>1.178023e-03</td>\n",
       "      <td>0.016321</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>1.385378e-07</td>\n",
       "      <td>1.545671e-07</td>\n",
       "      <td>9.113200e-08</td>\n",
       "      <td>1.811082e-07</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>1.595077e-05</td>\n",
       "      <td>1.229628e-04</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35cl</th>\n",
       "      <td>1.411301e-07</td>\n",
       "      <td>1.551792e-07</td>\n",
       "      <td>1.590261e-05</td>\n",
       "      <td>1.803219e-07</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>2.635139e-07</td>\n",
       "      <td>2.672150e-07</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3         4  \\\n",
       "token                                                                     \n",
       "$      4.554040e-03  1.322508e-06  5.524675e-03  3.675863e-03  0.000018   \n",
       "100    1.059977e-02  1.049358e-02  5.802063e-03  1.320193e-03  0.006939   \n",
       "12     7.131748e-03  2.287706e-03  1.863797e-03  2.552788e-03  0.000242   \n",
       "220    1.385378e-07  1.545671e-07  9.113200e-08  1.811082e-07  0.000003   \n",
       "35cl   1.411301e-07  1.551792e-07  1.590261e-05  1.803219e-07  0.000028   \n",
       "\n",
       "                  5             6       sum  highest_prob_topic  \n",
       "token                                                            \n",
       "$      6.960281e-05  7.256850e-03  0.021100                   7  \n",
       "100    2.476366e-03  1.348264e-02  0.051114                   7  \n",
       "12     1.064249e-03  1.178023e-03  0.016321                   1  \n",
       "220    1.595077e-05  1.229628e-04  0.000143                   7  \n",
       "35cl   2.635139e-07  2.672150e-07  0.000045                   5  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_topic_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic25_terms = term_topic_matrix[term_topic_matrix.highest_prob_topic.isin([2,5])].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic2_terms_sorted = term_topic_matrix[term_topic_matrix.highest_prob_topic == 2].\\\n",
    "    reset_index().sort_values(by=1, ascending=False)['token'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic5_terms_sorted = term_topic_matrix[term_topic_matrix.highest_prob_topic == 5].\\\n",
    "    reset_index().sort_values(by=4, ascending=False)['token'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_term_dict = Dictionary([topic25_terms])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(2277 unique tokens: ['+', '002', '003', '004', '005']...)\n"
     ]
    }
   ],
   "source": [
    "print(profile_term_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic2_dict = Dictionary([topic2_terms_sorted])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(995 unique tokens: ['+', '003', '005', '006', '100~~']...)\n"
     ]
    }
   ],
   "source": [
    "print(topic2_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic2_dict_top500 = Dictionary([topic2_terms_sorted[0:500]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(500 unique tokens: ['+', '105', '10yo', '110', '115']...)\n"
     ]
    }
   ],
   "source": [
    "print(topic2_dict_top500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save off the Dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_term_dict.save(os.getenv('DOMINO_WORKING_DIR') + '/models/tastingnotes_dictionary.gendict')\n",
    "topic2_dict.save(os.getenv('DOMINO_WORKING_DIR') + '/models/topic2_dictionary.gendict')\n",
    "topic2_dict_top500.save(os.getenv('DOMINO_WORKING_DIR') + '/models/topic2_top500_dictionary.gendict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Per-Token Inferred Topic from LDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
